# Justin-Smith-Thesis

The purpose of this thesis is to give people with speech disabilities, specifically
young children, their own unique voice. Many people who fit this criteria struggle with
communication throughout their academic experience. The current solution to this prob-
lem is using communication software that enables users to select images pertaining to
what they want to communicate. Current implementations of this software do not allow
students the flexibility to select voices that are personal to them, and may end up using a
voice identical to another student. This thesis proposes a text-to-speech model that takes
voice inputs to create a unique voice that can be used by the students’ preferred aug-
mentative/alternative communication (AAC) device. Existing approaches require long
speech inputs for training to maintain accuracy, whereas in this proposed model the
length of these inputs is shortened, but the quantity of inputs is increased to maintain
model accuracy. Another shortcoming of current solutions that this thesis addresses is
that a notable number of people with disabilities using this communication software are
completely non-verbal. In these cases, voice inputs from the parents of the students can
be collected to generate an appropriate, unique voice for the student to adjust to their
liking. The assimilated voice from the parents’ speech inputs will not reflect the students
perfectly, so hyperparameters can be adjusted at will to create a voice the student can
call their own.

<img width="959" height="539" alt="image" src="https://github.com/user-attachments/assets/b2201b5c-6903-4e8c-b47e-061a6202106d" />

<img width="959" height="539" alt="image" src="https://github.com/user-attachments/assets/7cd2b218-be22-42a9-819f-831f22def636" />

[media1.wav](https://github.com/user-attachments/files/22934788/media1.wav)
